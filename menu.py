"""
Sistema de Detecci√≥n EPP con YOLO
Men√∫ Principal - Gesti√≥n de detecciones en tiempo real y por video
"""

import os
import sys
from pathlib import Path
from ultralytics import YOLO
import cv2


class MenuPrincipal:
    """Men√∫ interactivo para el sistema de detecci√≥n EPP"""
    
    def __init__(self):
        self.model_path = self.buscar_modelo()
        self.running = True
        
    def buscar_modelo(self):
        """Busca el modelo disponible"""
        modelos_posibles = [
            "best.pt",
            "best.onnx",
            "../best.pt",
            "C:\\Users\\Angel Del C\\Desktop\\OroParaIA\\best.pt"
        ]
        
        for modelo in modelos_posibles:
            if Path(modelo).exists():
                return modelo
        
        return None
    
    def limpiar_pantalla(self):
        """Limpia la pantalla de la consola"""
        os.system('cls' if os.name == 'nt' else 'clear')
    
    def mostrar_menu(self):
        """Muestra el men√∫ principal"""
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 15 + "üõ°Ô∏è  SISTEMA DE DETECCI√ìN EPP üõ°Ô∏è")
        print("=" * 70)
        print()
        
        if self.model_path:
            print(f"üì¶ Modelo actual: {self.model_path}")
        else:
            print("‚ö†Ô∏è  Advertencia: No se encontr√≥ ning√∫n modelo")
        
        print()
        print("-" * 70)
        print("  [1] üìπ Detecci√≥n en Tiempo Real (C√°mara)")
        print("  [2] üé¨ Detecci√≥n por Video Configurable")
        print("  [3] üö® Alerta de EPP Faltante (C√°mara/Video)")
        print("  [4] ‚öôÔ∏è  Optimizar Modelo para Jetson Nano")
        print("  [5] üìä Cambiar Modelo")
        print("  [6] ‚ùå Salir")
        print("-" * 70)
        print()
    
    def deteccion_tiempo_real(self):
        """Ejecuta detecci√≥n en tiempo real con la c√°mara"""
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 20 + "üìπ DETECCI√ìN EN TIEMPO REAL")
        print("=" * 70)
        print()
        
        if not self.model_path:
            print("‚ùå Error: No hay modelo disponible")
            input("\nPresiona Enter para continuar...")
            return
        
        print(f"üîÑ Cargando modelo: {self.model_path}")
        print()
        
        try:
            # Cargar modelo
            model = YOLO(self.model_path)
            print("‚úÖ Modelo cargado correctamente")
            print()
            
            # Abrir c√°mara
            print("üì∑ Iniciando c√°mara...")
            cap = cv2.VideoCapture(0)
            
            if not cap.isOpened():
                print("‚ùå Error: No se puede acceder a la c√°mara")
                input("\nPresiona Enter para continuar...")
                return
            
            print("‚úÖ C√°mara iniciada")
            print()
            print("-" * 70)
            print("üí° Instrucciones:")
            print("   ‚Ä¢ Presiona [ESC] para salir")
            print("   ‚Ä¢ Presiona [S] para tomar captura")
            print("-" * 70)
            print()
            input("Presiona Enter para comenzar...")
            
            frame_count = 0
            captures_dir = Path("captures")
            captures_dir.mkdir(exist_ok=True)
            
            while cap.isOpened():
                # Leer frame del video (IGUAL que main.py)
                ret, frame = cap.read()
                if not ret:
                    print("‚ö†Ô∏è  No se pudo leer el frame")
                    break
                
                # Realizar inferencia de YOLO (IGUAL que main.py)
                results = model(frame)
                
                # Extraer resultados anotados (IGUAL que main.py)
                annotated_frame = results[0].plot()
                
                # Agregar contador de frames
                frame_count += 1
                cv2.putText(annotated_frame, f"Frame: {frame_count}", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(annotated_frame, "ESC: Salir | S: Captura", (10, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # Mostrar frame
                cv2.imshow("Detecci√≥n EPP - Tiempo Real", annotated_frame)
                
                # Controles de teclado
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    print("\nüõë Deteniendo detecci√≥n...")
                    break
                elif key == ord('s') or key == ord('S'):  # Captura
                    from datetime import datetime
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    capture_path = captures_dir / f"capture_{timestamp}.jpg"
                    cv2.imwrite(str(capture_path), annotated_frame)
                    print(f"üì∏ Captura guardada: {capture_path}")
            
            # Limpiar
            cap.release()
            cv2.destroyAllWindows()
            
            print("\n‚úÖ Detecci√≥n finalizada")
            print(f"üìä Total de frames procesados: {frame_count}")
            
        except Exception as e:
            print(f"\n‚ùå Error: {e}")
        
        input("\nPresiona Enter para continuar...")
    
    def deteccion_por_video(self):
        """Ejecuta detecci√≥n configurable sobre un archivo de video"""
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 15 + "üé¨ DETECCI√ìN POR VIDEO CONFIGURABLE")
        print("=" * 70)
        print()
        
        if not self.model_path:
            print("‚ùå Error: No hay modelo disponible")
            input("\nPresiona Enter para continuar...")
            return
        
        # PASO 1: Configurar clases a detectar
        clases_objetivo = self._configurar_clases_interactivo()
        
        if clases_objetivo is None:
            print("\n‚ùå Configuraci√≥n cancelada")
            input("\nPresiona Enter para continuar...")
            return
        
        # PASO 2: Solicitar ruta del video
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 20 + "üìÅ SELECCI√ìN DE VIDEO")
        print("=" * 70)
        print()
        if clases_objetivo:
            print(f"üéØ Detectando: {', '.join(clases_objetivo[:5])}{'...' if len(clases_objetivo) > 5 else ''}")
        else:
            print("üéØ Detectando: TODAS las clases")
        print()
        print("Ingresa la ruta del video a procesar:")
        print("(Puedes arrastrar el archivo aqu√≠)")
        print()
        video_path = input("Ruta del video: ").strip().strip('"')
        
        if not Path(video_path).exists():
            print(f"\n‚ùå Error: No se encuentra el archivo {video_path}")
            input("\nPresiona Enter para continuar...")
            return
        
        print()
        print("-" * 70)
        print("‚öôÔ∏è  OPCIONES DE PROCESAMIENTO")
        print("-" * 70)
        
        print("\n¬øGuardar video procesado? (s/n): ", end="")
        guardar_video = input().lower().strip() == 's'
        
        print("¬øMostrar video durante procesamiento? (s/n): ", end="")
        mostrar_video = input().lower().strip() == 's'
        
        print("Umbral de confianza (0.1-1.0, recomendado 0.25-0.35): ", end="")
        try:
            conf_threshold = float(input())
            if conf_threshold < 0.1 or conf_threshold > 1.0:
                conf_threshold = 0.25
        except:
            conf_threshold = 0.25
        
        print()
        print("-" * 70)
        print("üîÑ Iniciando procesamiento...")
        print("-" * 70)
        print()
        
        # PASO 3: Procesar video con funcionalidad dual
        self._procesar_video_configurable(
            video_path=video_path,
            clases_objetivo=clases_objetivo,
            conf_threshold=conf_threshold,
            guardar_video=guardar_video,
            mostrar_video=mostrar_video
        )
        
        input("\nPresiona Enter para continuar...")
    
    def _deteccion_basica_video(self, video_path, guardar_video, mostrar_video, skip_frames):
        """Detecci√≥n b√°sica de video - SIMPLIFICADO como main.py"""
        print("\nüîÑ Cargando modelo...")
        model = YOLO(self.model_path)
        print("‚úÖ Modelo cargado\n")
        
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print("‚ùå Error al abrir el video")
            return
        
        # Informaci√≥n del video
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"üìä FPS: {fps} | Resoluci√≥n: {width}x{height} | Frames: {total_frames}")
        print(f"‚öôÔ∏è  Procesando cada {skip_frames} frame(s)")
        print()
        
        # Video de salida
        out = None
        if guardar_video:
            output_path = Path("detections") / f"output_{Path(video_path).stem}.mp4"
            output_path.parent.mkdir(exist_ok=True)
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
            print(f"üíæ Guardando en: {output_path}")
        
        print("üé¨ Procesando video...")
        if mostrar_video:
            print("   Presiona 'Q' para detener")
        print()
        
        frame_number = 0
        processed = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_number += 1
            
            # Saltar frames si es necesario
            if skip_frames > 1 and frame_number % skip_frames != 0:
                if out:
                    out.write(frame)
                continue
            
            # Realizar inferencia de YOLO (IGUAL que main.py)
            results = model(frame)
            
            # Extraer resultados anotados (IGUAL que main.py)
            annotated_frame = results[0].plot()
            
            processed += 1
            
            if out:
                out.write(annotated_frame)
            
            if mostrar_video:
                cv2.imshow('Procesando Video', annotated_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            if processed % 30 == 0 and processed > 0:
                progress = (frame_number / total_frames) * 100
                print(f"  Progreso: {progress:.1f}% ({frame_number}/{total_frames}) - Procesados: {processed}")
        
        cap.release()
        if out:
            out.release()
            print(f"\n‚úÖ Video guardado: {output_path}")
        if mostrar_video:
            cv2.destroyAllWindows()
        
        print(f"‚úÖ Procesamiento completado: {processed} frames procesados")
    
    def optimizar_modelo(self):
        """Optimiza el modelo para Jetson Nano"""
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 18 + "‚öôÔ∏è  OPTIMIZACI√ìN DE MODELO")
        print("=" * 70)
        print()
        
        if not self.model_path:
            print("‚ùå Error: No hay modelo disponible")
            input("\nPresiona Enter para continuar...")
            return
        
        print(f"üì¶ Modelo a optimizar: {self.model_path}")
        print()
        print("-" * 70)
        print("Este proceso exportar√° el modelo a:")
        print("  ‚Ä¢ ONNX (Compatible, recomendado)")
        print("  ‚Ä¢ TensorRT (M√°ximo rendimiento en Jetson)")
        print()
        print("‚ö†Ô∏è  NOTA: La conversi√≥n a TensorRT solo funciona")
        print("   correctamente en la Jetson Nano")
        print("-" * 70)
        print()
        
        confirmacion = input("¬øContinuar con la optimizaci√≥n? (s/n): ")
        
        if confirmacion.lower().strip() != 's':
            print("\n‚ùå Optimizaci√≥n cancelada")
            input("\nPresiona Enter para continuar...")
            return
        
        print()
        print("üîÑ Iniciando optimizaci√≥n...")
        print()
        
        try:
            from Optimized_model import optimize_model_for_jetson
            
            optimize_model_for_jetson(self.model_path, "yolo11s_jetson")
            
            print("\n‚úÖ Optimizaci√≥n completada")
            
        except Exception as e:
            print(f"\n‚ùå Error durante la optimizaci√≥n: {e}")
        
        input("\nPresiona Enter para continuar...")
    
    def _configurar_clases_interactivo(self):
        """Configuraci√≥n interactiva de clases para detecci√≥n"""
        # Clases disponibles
        CLASES_DISPONIBLES = {
            'EPP': ['Gloves', 'Goggles', 'Hardhat', 'Mask', 'Safety Vest'],
            'NO_EPP': ['NO-Gloves', 'NO-Goggles', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest'],
            'OTROS': ['Person', 'Fall-Detected', 'Ladder', 'Safety Cone']
        }
        
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 15 + "üéØ CONFIGURACI√ìN DE CLASES A DETECTAR")
        print("=" * 70)
        print()
        
        # Mostrar todas las clases
        todas_clases = []
        idx = 1
        
        print("üü¢ EPP (Equipo de Protecci√≥n Personal):")
        for clase in CLASES_DISPONIBLES['EPP']:
            print(f"   [{idx:2d}] {clase}")
            todas_clases.append(clase)
            idx += 1
        
        print()
        print("üî¥ NO-EPP (Sin Equipo):")
        for clase in CLASES_DISPONIBLES['NO_EPP']:
            print(f"   [{idx:2d}] {clase}")
            todas_clases.append(clase)
            idx += 1
        
        print()
        print("üü° Otros:")
        for clase in CLASES_DISPONIBLES['OTROS']:
            print(f"   [{idx:2d}] {clase}")
            todas_clases.append(clase)
            idx += 1
        
        print()
        print("=" * 70)
        print("üí° COMANDOS DISPONIBLES:")
        print("=" * 70)
        print("  ‚Ä¢ N√∫mero (1-14)  ‚Üí Agregar/Remover esa clase")
        print("  ‚Ä¢ 'todo'         ‚Üí Agregar todas las clases")
        print("  ‚Ä¢ 'ver'          ‚Üí Ver tu lista actual")
        print("  ‚Ä¢ 'limpiar'      ‚Üí Vaciar la lista")
        print("  ‚Ä¢ 'iniciar'      ‚Üí Comenzar detecci√≥n")
        print("  ‚Ä¢ 'cancelar'     ‚Üí Volver al men√∫")
        print("=" * 70)
        print()
        
        clases_seleccionadas = []
        
        while True:
            # Mostrar estado actual
            if clases_seleccionadas:
                print(f"\nüìã Clases seleccionadas ({len(clases_seleccionadas)}):")
                print(f"   {', '.join(clases_seleccionadas)}")
            else:
                print(f"\nüìã Lista vac√≠a (0 clases seleccionadas)")
            
            comando = input("\n‚û§ Comando: ").strip().lower()
            
            if comando == 'iniciar':
                if not clases_seleccionadas:
                    print("\n‚ö†Ô∏è  No has seleccionado ninguna clase.")
                    print("¬øDetectar TODAS las clases? (s/n): ", end="")
                    if input().lower().strip() == 's':
                        return None  # None = detectar todo
                    else:
                        continue
                return clases_seleccionadas
            
            elif comando == 'cancelar':
                return None
            
            elif comando == 'todo':
                clases_seleccionadas = todas_clases.copy()
                print(f"‚úÖ Se agregaron TODAS las clases ({len(clases_seleccionadas)})")
            
            elif comando == 'ver':
                if clases_seleccionadas:
                    print("\n" + "="*50)
                    print("üìã TU LISTA ACTUAL:")
                    print("="*50)
                    for i, clase in enumerate(clases_seleccionadas, 1):
                        print(f"   {i:2d}. {clase}")
                    print("="*50)
                else:
                    print("\n‚ùå La lista est√° vac√≠a")
            
            elif comando == 'limpiar':
                clases_seleccionadas.clear()
                print("‚úÖ Lista limpiada")
            
            else:
                try:
                    num = int(comando)
                    if 1 <= num <= len(todas_clases):
                        clase = todas_clases[num - 1]
                        if clase in clases_seleccionadas:
                            clases_seleccionadas.remove(clase)
                            print(f"‚ûñ Removido: {clase}")
                        else:
                            clases_seleccionadas.append(clase)
                            print(f"‚úÖ Agregado: {clase}")
                    else:
                        print(f"‚ùå N√∫mero fuera de rango (1-{len(todas_clases)})")
                except ValueError:
                    print("‚ùå Comando no reconocido")
                    print("   Usa: n√∫mero, 'todo', 'ver', 'limpiar', 'iniciar' o 'cancelar'")
    
    def cambiar_modelo(self):
        """Permite cambiar el modelo a utilizar"""
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 22 + "üìä CAMBIAR MODELO")
        print("=" * 70)
        print()
        
        print("Ingresa la ruta del modelo (.pt, .onnx, .engine):")
        print("(Puedes arrastrar el archivo aqu√≠)")
        print()
        nuevo_modelo = input("Ruta del modelo: ").strip().strip('"')
        
        if not Path(nuevo_modelo).exists():
            print(f"\n‚ùå Error: No se encuentra el archivo {nuevo_modelo}")
            input("\nPresiona Enter para continuar...")
            return
        
        # Verificar que sea un modelo v√°lido
        extensiones_validas = ['.pt', '.onnx', '.engine']
        if not any(nuevo_modelo.endswith(ext) for ext in extensiones_validas):
            print(f"\n‚ö†Ô∏è  Advertencia: El archivo no tiene una extensi√≥n reconocida")
            print(f"   Extensiones v√°lidas: {', '.join(extensiones_validas)}")
            confirmacion = input("\n¬øContinuar de todas formas? (s/n): ")
            if confirmacion.lower().strip() != 's':
                print("\n‚ùå Cambio cancelado")
                input("\nPresiona Enter para continuar...")
                return
        
        self.model_path = nuevo_modelo
        print(f"\n‚úÖ Modelo cambiado correctamente")
        print(f"üì¶ Nuevo modelo: {self.model_path}")
        
        input("\nPresiona Enter para continuar...")
    
    def alerta_epp_faltante(self):
        """Sistema de alerta de EPP faltante"""
        self.limpiar_pantalla()
        print("=" * 70)
        print(" " * 18 + "üö® ALERTA DE EPP FALTANTE")
        print("=" * 70)
        print()
        
        if not self.model_path:
            print("‚ùå Error: No hay modelo disponible")
            input("\nPresiona Enter para continuar...")
            return
        
        print("üìπ Selecciona la fuente:")
        print("  [1] C√°mara en tiempo real")
        print("  [2] Archivo de video")
        print()
        
        opcion = input("Opci√≥n (1-2): ").strip()
        
        if opcion == '1':
            source = 0
        elif opcion == '2':
            print()
            print("üìÅ Ingresa la ruta del video:")
            source = input("Ruta: ").strip().strip('"')
            if not Path(source).exists():
                print(f"\n‚ùå Error: No se encuentra el archivo {source}")
                input("\nPresiona Enter para continuar...")
                return
        else:
            print("\n‚ùå Opci√≥n no v√°lida")
            input("\nPresiona Enter para continuar...")
            return
        
        try:
            from alerta_epp_faltante import main_video_alertas
            main_video_alertas(self.model_path, source)
        except Exception as e:
            print(f"\n‚ùå Error: {e}")
        
        input("\nPresiona Enter para continuar...")
    
    def ejecutar(self):
        """Bucle principal del men√∫"""
        while self.running:
            self.mostrar_menu()
            
            try:
                opcion = input("Selecciona una opci√≥n (1-6): ").strip()
                
                if opcion == '1':
                    self.deteccion_tiempo_real()
                elif opcion == '2':
                    self.deteccion_por_video()
                elif opcion == '3':
                    self.alerta_epp_faltante()
                elif opcion == '4':
                    self.optimizar_modelo()
                elif opcion == '5':
                    self.cambiar_modelo()
                elif opcion == '6':
                    self.limpiar_pantalla()
                    print("\nüëã ¬°Hasta pronto!")
                    print()
                    self.running = False
                else:
                    print("\n‚ö†Ô∏è  Opci√≥n no v√°lida. Intenta de nuevo.")
                    input("\nPresiona Enter para continuar...")
                    
            except KeyboardInterrupt:
                print("\n\n‚ö†Ô∏è  Interrupci√≥n detectada")
                print("¬øDeseas salir? (s/n): ", end="")
                if input().lower().strip() == 's':
                    self.running = False
            except Exception as e:
                print(f"\n‚ùå Error inesperado: {e}")
                input("\nPresiona Enter para continuar...")


def main():
    """Funci√≥n principal"""
    try:
        menu = MenuPrincipal()
        menu.ejecutar()
    except Exception as e:
        print(f"\n‚ùå Error fatal: {e}")
        input("\nPresiona Enter para salir...")


if __name__ == "__main__":
    main()
